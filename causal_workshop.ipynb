{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "causal_workshop.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ckbjimmy/2019_tokyo/blob/master/causal_workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "T0NWGbpnV1bT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Introduction to Causal Inference Workshop\n",
        "\n",
        "Hands-on Workshops by Satoshi Kimura / Wei-Hung Weng / Ryo Uchimido\n",
        "\n",
        "March 7, 2019 @ TMDU\n",
        "\n",
        "\n",
        "---\n",
        "- [`doWhy` GitHub repo](https://github.com/Microsoft/dowhy)\n",
        "- [`doWhy` document](https://causalinference.gitlab.io/dowhy/)\n",
        "- Before running all cells, please go to `FILE > Save a copy in Drive` to save the colab notebook to your own Google Drive."
      ]
    },
    {
      "metadata": {
        "id": "EwIDXHM2WWel",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Install dependencies\n"
      ]
    },
    {
      "metadata": {
        "id": "OIywWHOvLpK6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%capture \n",
        "!git clone https://github.com/Microsoft/dowhy.git\n",
        "!sudo apt install graphviz libgraphviz-dev graphviz-dev pkg-config\n",
        "!pip install pygraphviz \\\n",
        " --install-option=\"--include-path=/usr/include/graphviz\" \\\n",
        " --install-option=\"--library-path=/usr/lib/graphviz/\"\n",
        "!pip install -r ./dowhy/requirements.txt\n",
        "!pip install --upgrade pandas\n",
        "!pip install --upgrade statsmodels\n",
        "!python ./dowhy/setup.py install\n",
        "!wget -P ./dowhy/dowhy/causal_estimators/ \\\n",
        "https://raw.githubusercontent.com/ckbjimmy/2019_tokyo/master/logistic_regression_estimator.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7Ffxdh8umk-p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "After running the installation cell, please go to `Runtime > Restart runtime` to reload the updated packages."
      ]
    },
    {
      "metadata": {
        "id": "slp2jsuUXCa6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create a data simulator and define a graph"
      ]
    },
    {
      "metadata": {
        "id": "0Jjek0bmVe7O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "class DataSimulator(object):\n",
        "    def __init__(self):\n",
        "        # Specify the model parameters\n",
        "        self.sample_size = 5000\n",
        "\n",
        "        # Specify the prevalence of A (exposure)\n",
        "        self.p_A = 0.2\n",
        "\n",
        "        # Parameters for the odds of S (selection)\n",
        "        self.g0 = np.log(0.10/(1 - 0.10)) # log odds of S for ref group (A = 0 and U = 0)\n",
        "        self.g1 = np.log(5.0) # log OR for effect of A on log odds of selection (OR = 5.0)\n",
        "        self.g2 = np.log(5.0) # log OR for effect of U on log odds of selection (OR = 5.0)\n",
        "        self.g3 = np.log(1.0)  # log OR for interaction between A and U on    (OR = 5.0)\n",
        "\n",
        "        # Parameters for the odds of Y (outcome)\n",
        "        # Is S = 0 for reference group correct?\n",
        "        self.b0 = np.log(0.05/(1 - 0.05)) #log odds of Y for ref group (A = 0, U = 0, and S = 0)\n",
        "        self.b1 = np.log(1.0) #log OR for effect of A on log odds of Y (OR = 1.0)\n",
        "        self.b2 = np.log(5.0) #log OR for effect of U on log odds of Y (OR = 5.0)\n",
        "    \n",
        "    def prob_C(self, A, U):\n",
        "        return np.exp(self.g0 + self.g1*A)/(1 + np.exp(self.g0 + self.g1*A))\n",
        "  \n",
        "    def prob_S(self, A, U):\n",
        "        return np.exp(self.g0 + self.g1*A + self.g2*U + self.g3*U*A) / (1 + np.exp(self.g0 + self.g1*A + self.g2*U + self.g3*U*A))\n",
        "\n",
        "    def prob_Y(self, A, U):\n",
        "        return np.exp(self.b0 + self.b1*A +  self.b2*U) / (1 + np.exp(self.b0 + self.b1*A + self.b2*U))\n",
        "      \n",
        "    def get_graph(self, task):\n",
        "        if task == 'confounder':\n",
        "            g = '''\n",
        "            graph [\n",
        "            directed 1\n",
        "            node[id \"A\" label \"A\"]\n",
        "            node[id \"Y\" label \"Y\"]\n",
        "            node[id \"C\" label \"C\"]\n",
        "            edge[source \"A\" target \"Y\" weight 1]\n",
        "            edge[source \"C\" target \"A\" weight 1]\n",
        "            edge[source \"C\" target \"Y\" weight 1]\n",
        "            ]\n",
        "            '''\n",
        "\n",
        "            d = '''\n",
        "            digraph {\n",
        "            A -> Y;\n",
        "            C -> A;\n",
        "            C -> Y;\n",
        "            }\n",
        "            '''\n",
        "\n",
        "        elif task == 'collider':\n",
        "            g = '''\n",
        "            graph [\n",
        "            directed 1\n",
        "            node[id \"A\" label \"A\"]\n",
        "            node[id \"Y\" label \"Y\"]\n",
        "            node[id \"C\" label \"C\"]\n",
        "            node[id \"S\" label \"S\"]\n",
        "            edge[source \"A\" target \"Y\" weight 1]\n",
        "            edge[source \"A\" target \"S\" weight 1]\n",
        "            edge[source \"Y\" target \"S\" weight 1]\n",
        "            edge[source \"C\" target \"A\" weight 1]\n",
        "            edge[source \"C\" target \"Y\" weight 1]\n",
        "            ]\n",
        "            '''\n",
        "\n",
        "            d = '''\n",
        "            digraph {\n",
        "            A -> Y;\n",
        "            A -> S;\n",
        "            C -> A;\n",
        "            C -> Y;\n",
        "            Y -> S;\n",
        "            U[label=\"Unobserved Confounders\"];\n",
        "            U -> A;\n",
        "            U -> Y;\n",
        "            }\n",
        "            '''\n",
        "            \n",
        "        return g, d\n",
        "\n",
        "    def get_data(self, task):\n",
        "        g, d = self.get_graph(task)\n",
        "        ls_A = stats.binom.rvs(size=self.sample_size, n=1, p=self.p_A)\n",
        "        ls_U = stats.norm.rvs(size=self.sample_size, loc=0, scale=1)\n",
        "        p_S = [self.prob_S(ls_A[i], ls_U[i]) for i in range(self.sample_size)]\n",
        "        p_Y = [self.prob_Y(ls_A[i], ls_U[i]) for i in range(self.sample_size)]\n",
        "        \n",
        "        if task == 'confounder':\n",
        "            return pd.DataFrame({\n",
        "                'A': ls_A, \n",
        "                'C': ls_U, \n",
        "                'prob_Y': p_Y, \n",
        "                'Y': stats.binom.rvs(size=self.sample_size, n=1, p=p_Y)\n",
        "            }, columns=['A', 'C', 'prob_Y', 'Y']), g, d\n",
        "          \n",
        "        elif task == 'collider':\n",
        "            return pd.DataFrame({\n",
        "                'A': ls_A, \n",
        "                'C': ls_U, \n",
        "                'prob_S': p_S,\n",
        "                'prob_Y': p_Y, \n",
        "                'S': stats.binom.rvs(size=self.sample_size, n=1, p=p_S),\n",
        "                'Y': stats.binom.rvs(size=self.sample_size, n=1, p=p_Y)\n",
        "            }, columns=['A', 'C', 'prob_S', 'prob_Y', 'S', 'Y']), g, d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JQFOkSX8XGyQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load packages and inspect data"
      ]
    },
    {
      "metadata": {
        "id": "LAbALlVwP0A7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('dowhy')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from IPython.display import Image, display\n",
        "\n",
        "from dowhy.do_why import CausalModel\n",
        "import dowhy.datasets\n",
        "from dowhy.do_samplers.kernel_density_sampler import KernelDensitySampler\n",
        "from dowhy.api.causal_data_frame import CausalDataFrame\n",
        "from statsmodels.api import OLS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IGUqmilaLq6A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # Using doWhy simulator\n",
        "# data = dowhy.datasets.linear_dataset(\n",
        "#     beta=10,\n",
        "#     num_common_causes=5,\n",
        "#     num_instruments=2,\n",
        "#     num_samples=10000,\n",
        "#     treatment_is_binary=True)\n",
        "\n",
        "# data = dowhy.datasets.linear_dataset(beta=5,\n",
        "#         num_common_causes=1,\n",
        "#         num_instruments = 0,\n",
        "#         num_samples=1000,\n",
        "#         treatment_is_binary=True)\n",
        "# data['dot_graph'] = 'digraph { v ->y;X0-> v;X0-> y;}'\n",
        "\n",
        "# Simulate our own data\n",
        "\n",
        "task = 'collider' # change to 'confounder' for another graph\n",
        "\n",
        "sim = DataSimulator()\n",
        "data = {}\n",
        "data['df'], g, d = sim.get_data(task)\n",
        "data['treatment_name'] = 'A'\n",
        "data['outcome_name'] = 'Y'\n",
        "data['gml_graph'] = g.replace('\\n', '')\n",
        "data['dot_graph'] = d.replace('\\n', '')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cRMchwCXHOkg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z2zzWnnBfCPl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### If we don't consider removing the collider (S)"
      ]
    },
    {
      "metadata": {
        "id": "RF5g451Iev13",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = data['df']\n",
        "model = OLS(df['Y'], df[['C', 'A', 'S']])\n",
        "result = model.fit()\n",
        "result.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fTJwIHWhfIu0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Considering the collider (S) using causal graph"
      ]
    },
    {
      "metadata": {
        "id": "P1wNrpdGLwWr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create a causal model from the data and given graph.\n",
        "model = CausalModel(\n",
        "    data=data[\"df\"],\n",
        "    treatment=data[\"treatment_name\"],\n",
        "    outcome=data[\"outcome_name\"],\n",
        "    graph=data[\"gml_graph\"])\n",
        "\n",
        "model.view_model()\n",
        "display(Image(filename=\"causal_model.png\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gGnSUa0qkm_d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Identify causal effect and return target estimands\n",
        "identified_estimand = model.identify_effect()\n",
        "print(identified_estimand)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nhr-i0PdkueT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Estimate the target estimand using a statistical method.\n",
        "# estimate = model.estimate_effect(identified_estimand,\n",
        "#                                  method_name=\"backdoor.propensity_score_matching\")\n",
        "\n",
        "estimate = model.estimate_effect(\n",
        "    identified_estimand,\n",
        "    method_name=\"backdoor.logistic_regression\") # change to backdoor.linear_regression if the outcome is continuous\n",
        "\n",
        "print(estimate)\n",
        "print(\"Causal Estimate is \" + str(estimate.value))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s6wTL1mJlk3w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # Refute the obtained estimate using multiple robustness checks.\n",
        "refute_results = model.refute_estimate(identified_estimand, estimate,\n",
        "                                       method_name=\"random_common_cause\")\n",
        "\n",
        "print(refute_results)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MoHKC8K8fX5_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The estimated effect decrease from 0.0676 to 0.008."
      ]
    },
    {
      "metadata": {
        "id": "fcPhjNanIyP9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## `test mcmc do sampler.ipynb`"
      ]
    },
    {
      "metadata": {
        "id": "vdQSNS7xGAdM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = data['df']\n",
        "df['Y'] = df['Y'] + np.random.normal(size=len(df)) # without noise, the variance in Y|X, Z is zero, and mcmc fails."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nl66R01mIVut",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cdf = CausalDataFrame(df)\n",
        "cdf.causal.do(x={'A': 1}, \n",
        "              variable_types={'A': 'b', 'C': 'c', 'Y': 'c'}, \n",
        "              outcome='Y',\n",
        "              method='mcmc', \n",
        "              common_causes=['C'],\n",
        "              keep_original_treatment=True,\n",
        "              proceed_when_unidentifiable=True).groupby('A').mean().plot(y='Y', kind='bar')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6roHOeO9IXsv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cdf = CausalDataFrame(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fpxDxgAbIbfq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cdf_1 = cdf.causal.do(x={'A': 1}, \n",
        "              variable_types={'A': 'b', 'C': 'c', 'Y': 'b', 'S': 'b'}, \n",
        "              outcome='Y',\n",
        "              method='mcmc', \n",
        "              dot_graph=data['dot_graph'],\n",
        "              proceed_when_unidentifiable=True)\n",
        "\n",
        "cdf_0 = cdf.causal.do(x={'A': 0}, \n",
        "              variable_types={'A': 'b', 'C': 'c', 'Y': 'b', 'S': 'b'}, \n",
        "              outcome='Y',\n",
        "              method='mcmc', \n",
        "              dot_graph=data['dot_graph'],\n",
        "              proceed_when_unidentifiable=True,\n",
        "              use_previous_sampler=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dkFKLJzQIdUO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cdf_0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LgweqLNYIfCn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cdf_1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GVhgSzCCIlAX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(cdf_1['Y'] - cdf_0['Y']).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FNZ6-_PBIm5n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "1.96*(cdf_1['Y'] - cdf_0['Y']).std() / np.sqrt(len(cdf))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ivjywO8YIoj_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = OLS(df['Y'], df[['C', 'A']])\n",
        "result = model.fit()\n",
        "result.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3gh5Y6CWIsSp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cdf_do = cdf.causal.do(x={'A': 0}, \n",
        "              variable_types={'A': 'b', 'C': 'c', 'Y': 'c'}, \n",
        "              outcome='Y',\n",
        "              method='mcmc', \n",
        "              common_causes=['C'],\n",
        "              keep_original_treatment=True,\n",
        "              proceed_when_unidentifiable=True).groupby('A').mean().plot(y='Y', kind='bar')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iYvOTbkwItpR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cdf_do"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hTrBfq5X1Wn_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Hands-on exercise: NHEFS data"
      ]
    },
    {
      "metadata": {
        "id": "BSCCg4sv0bGF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nhefs = pd.ExcelFile('https://www.dropbox.com/s/nchp1pezska7bim/nhefs.xlsx?dl=1').parse('2017')\n",
        "nhefs.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nCZPnwHh0x0Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "g = '''\n",
        "graph [\n",
        "directed 1\n",
        "node[id \"qsmk\" label \"qsmk\"]\n",
        "node[id \"wt82_71\" label \"wt82_71\"]\n",
        "node[id \"age\" label \"age\"]\n",
        "node[id \"diabetes\" label \"diabetes\"]\n",
        "node[id \"exercise\" label \"exercise\"]\n",
        "edge[source \"qsmk\" target \"wt82_71\" weight 1]\n",
        "edge[source \"qsmk\" target \"exercise\" weight 1]\n",
        "edge[source \"wt82_71\" target \"exercise\" weight 1]\n",
        "edge[source \"age\" target \"qsmk\" weight 1]\n",
        "edge[source \"age\" target \"wt82_71\" weight 1]\n",
        "edge[source \"diabetes\" target \"qsmk\" weight 1]\n",
        "edge[source \"diabetes\" target \"wt82_71\" weight 1]\n",
        "]\n",
        "'''\n",
        "\n",
        "d = '''\n",
        "digraph {\n",
        "qsmk -> wt82_71;\n",
        "qsmk -> exercise;\n",
        "age -> qsmk;\n",
        "age -> wt82_71;\n",
        "diabetes -> qsmk;\n",
        "diabetes -> wt82_71;\n",
        "wt82_71 -> exercise;\n",
        "U[label=\"Unobserved Confounders\"];\n",
        "U -> qsmk;\n",
        "U -> wt82_71;\n",
        "}\n",
        "'''\n",
        "\n",
        "selected = ['age', 'diabetes', 'qsmk', 'wt82_71', 'exercise']\n",
        "\n",
        "data = {}\n",
        "data['df'] = nhefs[selected]\n",
        "data['treatment_name'] = 'qsmk'\n",
        "data['outcome_name'] = 'wt82_71'\n",
        "data['gml_graph'] = g.replace('\\n', '')\n",
        "data['dot_graph'] = d.replace('\\n', '')\n",
        "\n",
        "model = CausalModel(\n",
        "    data=data[\"df\"],\n",
        "    treatment=data[\"treatment_name\"],\n",
        "    outcome=data[\"outcome_name\"],\n",
        "    graph=data[\"gml_graph\"])\n",
        "\n",
        "model.view_model()\n",
        "display(Image(filename=\"causal_model.png\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TpErJ32aefgL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "identified_estimand = model.identify_effect()\n",
        "print(identified_estimand)\n",
        "\n",
        "estimate = model.estimate_effect(\n",
        "    identified_estimand,\n",
        "    method_name=\"backdoor.linear_regression\",\n",
        "    test_significance=True)\n",
        "\n",
        "print(estimate)\n",
        "print(\"Causal Estimate is \" + str(estimate.value))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9NB0vjlPoV3I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nhefs[selected].isnull().values.any()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Omnf9mMMl-CC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import Imputer\n",
        "\n",
        "nhefs_imputed = nhefs\n",
        "for i in selected:\n",
        "  imputer = Imputer(missing_values=\"NaN\", strategy=\"mean\")\n",
        "  nhefs_imputed[i] = imputer.fit_transform(nhefs[[i]]) \n",
        "\n",
        "data = {}\n",
        "data['df'] = nhefs_imputed\n",
        "data['treatment_name'] = 'qsmk'\n",
        "data['outcome_name'] = 'wt82_71'\n",
        "data['gml_graph'] = g.replace('\\n', '')\n",
        "data['dot_graph'] = d.replace('\\n', '')\n",
        "\n",
        "model = CausalModel(\n",
        "    data=data[\"df\"],\n",
        "    treatment=data[\"treatment_name\"],\n",
        "    outcome=data[\"outcome_name\"],\n",
        "    graph=data[\"gml_graph\"])\n",
        "\n",
        "model.view_model()\n",
        "display(Image(filename=\"causal_model.png\"))\n",
        "\n",
        "identified_estimand = model.identify_effect()\n",
        "print(identified_estimand)\n",
        "\n",
        "estimate = model.estimate_effect(\n",
        "    identified_estimand,\n",
        "    method_name=\"backdoor.linear_regression\",\n",
        "    test_significance=True)\n",
        "\n",
        "print(estimate)\n",
        "print(\"Causal Estimate is \" + str(estimate.value))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TVI-UQ1Vmuap",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}